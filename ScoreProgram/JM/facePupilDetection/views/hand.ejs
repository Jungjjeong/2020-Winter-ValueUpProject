<!-- <html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HandTEST</title>
</head>
<body>
    <body>
    <h2>Hello OpenCV.js</h2>
    <p id="status">OpenCV.js is loading...</p>

    <video id="videoInput" ></video>
    <img id="imageInput">
    <canvas id="canvasOutput"></canvas>

    <h1>End</h1>
    
    <script type="text/javascript" src="handTest.js"></script>
    <script async type="text/javascript" onload="openCvReady();" src="opencv.js"></script>
</body>
</html> -->

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js is loading...</p>
<div>
  <div class="videoBox">
    <video id="videoInput" playsinline style="
    -webkit-transform: scaleX(-1);
    transform: scaleX(-1);
    width: 500px;
    height: 500px;
    "></video>
      <input type="button" id="videoButton" value="videoStart">
  </div>
  <input type="button" id="detectButton" value="detectStart">
  <canvas id="canvasOutput"></canvas>
  <br>
  <input type="range" id="range1" min="0",max="255">
  <input type="range" id="range2">
  <input type="range" id="range3">
  <input type="range" id="range4">
</div>
<script type="text/javascript">
let videoButton = document.getElementById("videoButton");
let detectButton = document.getElementById("detectButton");
let rangeInput = document.getElementById("range1");

let videoWidth;
let videoHeight;
const VIDEO_SIZE = 500;


videoButton.onclick = async function(){
    let video = document.getElementById("videoInput"); // video is the id of video tag

    const stream = await navigator.mediaDevices.getUserMedia({
        'audio': true,
        'video': {
            // Only setting the video to a specified size in order to accommodate a
            // point cloud, so on mobile devices accept the default size.
            width: VIDEO_SIZE,
            height: VIDEO_SIZE
        },
    });
    
    video.srcObject = stream;
    video.play();
    // videoWidth = video.videoWidth;
    // videoHeight = video.videoHeight;
    // video.width = videoWidth;
    // video.height = videoHeight;
    video.width = 500;
    video.height = 500;
    video.videoHeight = 500;
    video.videoWidth = 500;
    console.log(video.videoWidth);
    console.log(video.videoHeight);
    console.log(video.width);
    console.log(video.height);

};

detectButton.onclick = function(){
    console.log("detection start!");
    let videoInput = document.getElementById("videoInput");
    let canvasOutput = document.getElementById("canvasOutput")

    src = new cv.Mat(videoInput.height, videoInput.width, cv.CV_8UC4);
    dst = new cv.Mat(videoInput.height, videoInput.width, cv.CV_8UC4);
    console.log(videoInput.height);
    console.log(videoInput.width);
    gray = new cv.Mat();
    filtered = new cv.Mat();
    cap = new cv.VideoCapture(videoInput);
    faces = new cv.RectVector();
    classifier = new cv.CascadeClassifier();

    classifier.load('haarcascade_frontalface_default.xml');

    cap.read(src);
    src.copyTo(dst);
    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);

    // const skinColorUpper = new cv.Mat(src.rows, src.cols, src.type(),[0,0, 0.8 * 255, 0.6 * 255]);
    // const skinColorLower = new cv.Mat(src.rows, src.cols, src.type(),[0,15, 0.1 * 255, 0.05 * 255]);
    let skinColorLower = new cv.Mat(src.rows, src.cols, src.type(), [0, 38, 80, 0]);
    let skinColorUpper = new cv.Mat(src.rows, src.cols, src.type(), [170, 150, 150, 255]);

    cv.inRange(dst,skinColorLower,skinColorUpper,filtered)

    // const imgHLS = cv.cvtColor(dst,gray,cv.COLOR_RGBA2GRAY);
    // const rangeMask = imgHLS.inRange(skinColorLower(0), skinColorUpper(15));
    // // remove noise
    // const blurred = rangeMask.blur(new cv.Size(10, 10));
    // const thresholded = blurred.threshold(
    //     200,
    //     255,
    //     cv.THRESH_BINARY
    // );

    // classifier.detectMultiScale(gray,faces,1.1,3,0);
    // for (let i = 0; i < faces.size(); ++i) {
    //         let face = faces.get(i);
    //         let point1 = new cv.Point(face.x, face.y);
    //         let point2 = new cv.Point(face.x + face.width, face.y + face.height);
    //         cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
    //     }
    cv.imshow("canvasOutput", filtered);
}

function onOpenCvReady() {
  document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
}
</script>
<script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>
</html>